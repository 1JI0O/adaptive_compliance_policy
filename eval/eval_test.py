"""
Evaluation with dataset replay.
"""
import sys
import pathlib
import os
import hydra
import torch
from omegaconf import OmegaConf
import pickle
import numpy as np
from collections import deque
from datetime import datetime
import zarr
import cv2

import yaml
from easydict import EasyDict as edict

# 1. ç®—å‡ºæ ¹ç›®å½•
ROOT_DIR = str(pathlib.Path(__file__).parent.parent.absolute())
PYRITE_ML_DIR = os.path.join(ROOT_DIR, 'PyriteML')

sys.path.append(ROOT_DIR)
sys.path.append(PYRITE_ML_DIR)
os.chdir(ROOT_DIR)

from PyriteML.diffusion_policy.workspace.base_workspace import BaseWorkspace
from PyriteML.diffusion_policy.policy.diffusion_unet_timm_mod1_policy import (
    DiffusionUnetTimmMod1Policy,
)
import PyriteUtility.spatial_math.spatial_utilities as su
from scipy.spatial.transform import Rotation as R

from PyriteUtility.computer_vision.imagecodecs_numcodecs import register_codecs

device = torch.device("cuda:6" if torch.cuda.is_available() else "cpu")

# ========================================
# é…ç½®è·¯å¾„
# ========================================
yaml_path = "/data/haoxiang/logs/acp_logs/2026.01.25_02.48.48_flipup_v3_conv_230/.hydra/config.yaml"
ckpt_path = "/data/haoxiang/logs/acp_logs/2026.01.25_02.48.48_flipup_v3_conv_230/checkpoints/latest.ckpt"
normalizer_path = "/data/haoxiang/logs/acp_logs/2026.01.25_02.48.48_flipup_v3_conv_230/sparse_normalizer.pkl"

# æ•°æ®é›†è·¯å¾„
dataset_path = "/data/haoxiang/acp/acp_processed/flipup_v3"  
episode_id = "episode_1" 

# è¶…å‚æ•°
n_action_steps = 1
sparse_obs_rgb_down_sample_steps = 1
sparse_obs_rgb_horizon = 2
sparse_obs_low_dim_down_sample_steps = 1
sparse_obs_low_dim_horizon = 3
sparse_obs_wrench_down_sample_steps = 5
sparse_obs_wrench_horizon = 32
sparse_action_horizon = 16
sparse_action_down_sample_steps = 1

# ========================================
# æ•°æ®åŠ è½½å™¨
# ========================================
class DatasetReplayer:
    """ä» zarr æ•°æ®é›†ä¸­åŠ è½½ episode æ•°æ®ç”¨äºå›æ”¾æµ‹è¯•"""
    
    def __init__(self, dataset_path, episode_id):
        self.dataset_path = dataset_path
        self.episode_id = episode_id
        self.load_episode()
        
    def load_episode(self):
        """åŠ è½½æŒ‡å®š episode çš„æ‰€æœ‰æ•°æ®"""
        print(f"Loading episode: {self.episode_id} from {self.dataset_path}")
        
        # æ‰“å¼€ zarr æ•°æ®é›†
        root = zarr.open(self.dataset_path, mode='r')
        ep_data = root['data'][self.episode_id]
        
        # è¯»å–æ‰€æœ‰æ•°æ®åˆ°å†…å­˜
        self.rgb_0 = ep_data['rgb_0'][:]                    # (T, H, W, 3)
        self.rgb_1 = ep_data['rgb_1'][:]                    # (T, H, W, 3)
        self.ts_pose_fb_0 = ep_data['ts_pose_fb_0'][:]      # (T, 7) [x,y,z,qw,qx,qy,qz]
        self.wrench_0 = ep_data['wrench_0'][:]              # (T, 6)
        self.wrench_filtered = ep_data['wrench_filtered'][:] if 'wrench_filtered' in ep_data else self.wrench_0
        
        # æ—¶é—´æˆ³
        self.rgb_time_stamps_0 = ep_data['rgb_time_stamps_0'][:]
        self.rgb_time_stamps_1 = ep_data['rgb_time_stamps_1'][:]
        self.robot_time_stamps_0 = ep_data['robot_time_stamps_0'][:]
        self.wrench_time_stamps_0 = ep_data['wrench_time_stamps_0'][:]
        
        # å¦‚æœæœ‰ virtual target å’Œ stiffnessï¼ˆåå¤„ç†åçš„æ•°æ®ï¼‰
        if 'ts_pose_virtual_target_0' in ep_data:
            self.ts_pose_vt_0 = ep_data['ts_pose_virtual_target_0'][:]
            self.stiffness_0 = ep_data['stiffness_0'][:]
        else:
            self.ts_pose_vt_0 = None
            self.stiffness_0 = None
        
        # self.total_steps = len(self.robot_time_stamps_0) # è¿™ä¸ªæœ‰å¤§é—®é¢˜ï¼
        self.total_steps = len(self.rgb_time_stamps_0)
        print(f"Loaded {self.total_steps} timesteps")
        print(f"  RGB_0 shape: {self.rgb_0.shape}")
        print(f"  RGB_1 shape: {self.rgb_1.shape}")
        print(f"  Pose shape: {self.ts_pose_fb_0.shape}")
        print(f"  Wrench shape: {self.wrench_filtered.shape}")
        
    # def get_obs_at_step(self, t):
    #     """
    #     è·å–ç¬¬ t æ­¥çš„è§‚æµ‹æ•°æ®
        
    #     Returns:
    #         rgb_0: (H, W, 3) uint8
    #         rgb_1: (H, W, 3) uint8
    #         pos: (3,) float
    #         rot6d: (6,) float
    #         wrench: (6,) float
    #     """
    #     # 1. RGB å›¾åƒ
    #     rgb_0 = self.rgb_0[t]  # (H, W, 3)
    #     rgb_1 = self.rgb_1[t]  # (H, W, 3)
        
    #     # 2. ä½ç½®å’Œæ—‹è½¬
    #     pose7 = self.ts_pose_fb_0[t]  # [x, y, z, qw, qx, qy, qz]
    #     pos = pose7[:3]
    #     quat = pose7[3:]  # [qw, qx, qy, qz]
        
    #     # è½¬æ¢ä¸º rotation 6d
    #     # quat æ ¼å¼ï¼š[qw, qx, qy, qz]
    #     r = R.from_quat([quat[1], quat[2], quat[3], quat[0]])  # scipy æ ¼å¼: [qx,qy,qz,qw]
    #     rot_mat = r.as_matrix()
    #     rot6d = su.SO3_to_rot6d(rot_mat)
        
    #     # 3. åŠ›/åŠ›çŸ©
    #     wrench = self.wrench_filtered[t]
        
    #     return rgb_0,rgb_1, pos, rot6d, wrench

    def get_obs_at_step(self, t):
        """
        ä¿®æ”¹åçš„é€»è¾‘ï¼šä»¥ç¬¬ t å¸§å›¾åƒçš„æ—¶é—´ä¸ºåŸºå‡†ï¼Œå¯¹é½å…¶ä»–ä¼ æ„Ÿå™¨æ•°æ®
        """
        # 1. ç¡®å®šåŸºå‡†æ—¶é—´ï¼šå½“å‰å›¾åƒçš„æ—¶é—´æˆ³
        query_time = self.rgb_time_stamps_0[t]
        
        # 2. è·å–å›¾åƒ
        rgb_0 = self.rgb_0[t]
        rgb_1 = self.rgb_1[t] # å‡è®¾ä½ åˆšæ‰å·²ç»æŒ‰æˆ‘çš„å»ºè®®æŠŠ rgb_1 é•¿åº¦å¯¹é½äº† rgb_0

        # 3. å¯¹é½æœºå™¨äººä½å§¿ (Robot Pose)
        # åœ¨ robot æ—¶é—´è½´é‡Œæ‰¾æœ€æ¥è¿‘ query_time çš„ç´¢å¼•
        robot_idx = np.searchsorted(self.robot_time_stamps_0, query_time)
        # é˜²æ­¢è¶Šç•Œ
        robot_idx = min(robot_idx, len(self.ts_pose_fb_0) - 1)
        pose7 = self.ts_pose_fb_0[robot_idx]
        
        # 4. å¯¹é½åŠ›çŸ© (Wrench)
        # åœ¨ wrench æ—¶é—´è½´é‡Œæ‰¾æœ€æ¥è¿‘ query_time çš„ç´¢å¼•
        wrench_idx = np.searchsorted(self.wrench_time_stamps_0, query_time)
        wrench_idx = min(wrench_idx, len(self.wrench_filtered) - 1)
        wrench = self.wrench_filtered[wrench_idx]

        # --- è½¬æ¢ä½å§¿åˆ° rotation 6d ---
        pos = pose7[:3]
        quat = pose7[3:] # [qw, qx, qy, qz]
        r = R.from_quat([quat[1], quat[2], quat[3], quat[0]]) # qx,qy,qz,qw
        rot6d = su.SO3_to_rot6d(r.as_matrix())
        
        # ğŸ”¥ å…³é”®ï¼šæŠŠè¿™ä¸ª robot_idx ä¼ å‡ºå»ï¼Œç»™ GT å¯¹æ¯”ç”¨
        return rgb_0, rgb_1, pos, rot6d, wrench, robot_idx
    
    # def get_ground_truth_action(self, t):
    #     """
    #     è·å–ç¬¬ t æ­¥çš„ ground truth åŠ¨ä½œï¼ˆå¦‚æœæœ‰ï¼‰
        
    #     Returns:
    #         pose_command: (7,) [x,y,z,qw,qx,qy,qz]
    #         pose_vt: (7,) æˆ– None
    #         stiffness: float æˆ– None
    #     """
    #     if self.ts_pose_vt_0 is not None:
    #         return self.ts_pose_fb_0[t], self.ts_pose_vt_0[t], self.stiffness_0[t]
    #     else:
    #         return self.ts_pose_fb_0[t], None, None

    # ä¿®æ”¹ DatasetReplayer ç±»çš„ get_ground_truth_action
    def get_ground_truth_action(self, robot_idx):
        """
        ä¸å†æ¥æ”¶ tï¼Œè€Œæ˜¯æ¥æ”¶å¯¹é½åçš„ robot_idx
        """
        if self.ts_pose_vt_0 is not None:
            return self.ts_pose_fb_0[robot_idx], self.ts_pose_vt_0[robot_idx], self.stiffness_0[robot_idx]
        else:
            return self.ts_pose_fb_0[robot_idx], None, None


# ========================================
# Buffer ç®¡ç†
# ========================================
buffer_rgb_0 = deque(maxlen=sparse_obs_rgb_horizon)
buffer_rgb_1 = deque(maxlen=sparse_obs_rgb_horizon)
buffer_pos = deque(maxlen=sparse_obs_low_dim_horizon)
buffer_rot = deque(maxlen=sparse_obs_low_dim_horizon)
buffer_wrench = deque(maxlen=sparse_obs_wrench_horizon)
action_queue = deque(maxlen=8)

def reset_buffers():
    buffer_rgb_0.clear()
    buffer_rgb_1.clear()
    buffer_pos.clear()
    buffer_rot.clear()
    buffer_wrench.clear()
    action_queue.clear()

OmegaConf.register_new_resolver(
    "now", 
    lambda pattern: datetime.now().strftime(pattern), 
    replace=True
)

# ========================================
# è¯„ä¼°ä¸»å‡½æ•°
# ========================================
def evaluate_with_dataset():
    # 1. åŠ è½½ policy
    cfg = OmegaConf.load(yaml_path)
    OmegaConf.resolve(cfg)
    policy = hydra.utils.instantiate(cfg.policy)
    
    if os.path.exists(normalizer_path):
        with open(normalizer_path, 'rb') as f:
            normalizer_data = pickle.load(f)
        policy.set_normalizer(normalizer_data)
    
    payload = torch.load(ckpt_path, map_location=device)
    policy.load_state_dict(payload['state_dicts']['ema_model'])
    policy = policy.to(device)
    policy.eval()
    
    # 2. åŠ è½½æ•°æ®é›†å›æ”¾å™¨
    replayer = DatasetReplayer(dataset_path, episode_id)
    
    # 3. ç»“æœè®°å½•
    results = {
        'predicted_actions': [],
        'ground_truth_actions': [],
        'predicted_vt': [],
        'ground_truth_vt': [],
        'predicted_stiffness': [],
        'ground_truth_stiffness': [],
    }
    
    print("=" * 60)
    print("Starting dataset replay evaluation...")
    print("=" * 60)
    
    with torch.inference_mode():
        for t in range(min(replayer.total_steps, 99999)):  # é™åˆ¶æµ‹è¯•æ­¥æ•°
            print(f"\nStep {t}/{replayer.total_steps} ---------------------")
            
            # ========================================
            # 1. ä»æ•°æ®é›†è·å–è§‚æµ‹ ä»¥åŠæ‹¿åˆ°ç´¢å¼•
            # ========================================
            rgb_0_raw, rgb_1_raw, end_pos, end_rot6d, wrench, robot_idx = replayer.get_obs_at_step(t)
            
            # å¤„ç† RGB å›¾åƒ
            # å‡è®¾æ•°æ®é›†ä¸­å·²ç»æ˜¯ 224x224ï¼Œå¦‚æœä¸æ˜¯éœ€è¦ resize
            if rgb_0_raw.shape[:2] != (224, 224):
                import cv2
                rgb_0_raw = cv2.resize(rgb_0_raw, (224, 224), interpolation=cv2.INTER_AREA)
            
            rgb_0 = rgb_0_raw.transpose(2, 0, 1)  # HWC -> CHW

            if rgb_1_raw.shape[:2] != (224, 224):
                import cv2
                rgb_1_raw = cv2.resize(rgb_1_raw, (224, 224), interpolation=cv2.INTER_AREA)
            
            rgb_1 = rgb_1_raw.transpose(2, 0, 1)  # HWC -> CHW
            
            # ========================================
            # 2. æ·»åŠ åˆ° buffer
            # ========================================
            if t % sparse_obs_rgb_down_sample_steps == 0:
                buffer_rgb_0.append(rgb_0)
                buffer_rgb_1.append(rgb_1)
            if t % sparse_obs_low_dim_down_sample_steps == 0:
                buffer_pos.append(end_pos)
                buffer_rot.append(end_rot6d)
            if t % sparse_obs_wrench_down_sample_steps == 0:
                buffer_wrench.append(wrench)
            
            # ç¬¬ä¸€å¸§å¡«å……
            if t == 0:
                while len(buffer_rgb_0) < sparse_obs_rgb_horizon:
                    buffer_rgb_0.append(rgb_0)
                while len(buffer_rgb_1) < sparse_obs_rgb_horizon:
                    buffer_rgb_1.append(rgb_1)
                while len(buffer_pos) < sparse_obs_low_dim_horizon:
                    buffer_pos.append(end_pos)
                while len(buffer_rot) < sparse_obs_low_dim_horizon:
                    buffer_rot.append(end_rot6d)
                while len(buffer_wrench) < sparse_obs_wrench_horizon:
                    buffer_wrench.append(wrench)
            
            # ç­‰å¾… buffer å¡«æ»¡
            if len(buffer_pos) < sparse_obs_low_dim_horizon:
                continue
            
            # ========================================
            # 3. é¢„æµ‹åŠ¨ä½œ
            # ========================================
            if len(action_queue) == 0:
                # obs_batch = {
                #     "sparse": {
                #         "rgb_0": torch.from_numpy(np.stack(list(buffer_rgb))).unsqueeze(0).float().to(device),
                #         "robot0_eef_pos": torch.from_numpy(np.stack(list(buffer_pos))).unsqueeze(0).float().to(device),
                #         "robot0_eef_rot_axis_angle": torch.from_numpy(np.stack(list(buffer_rot))).unsqueeze(0).float().to(device),
                #         "robot0_eef_wrench": torch.from_numpy(np.stack(list(buffer_wrench))).unsqueeze(0).float().to(device)
                #     }
                # }

                # ========================================
                # âœ… æ–°å¢ï¼šè§‚æµ‹ç›¸å¯¹åŒ–ï¼ˆå’Œè®­ç»ƒæ—¶ä¸€è‡´ï¼‰
                # ========================================
                # è·å–åŸºå‡†å¸§ï¼ˆè§‚æµ‹åºåˆ—çš„æœ€åä¸€å¸§ï¼‰
                base_pos = buffer_pos[-1]
                base_rot6d = buffer_rot[-1]
                base_pose9 = np.concatenate([base_pos, base_rot6d])
                base_SE3 = su.pose9_to_SE3(base_pose9)
                
                # å°†æ‰€æœ‰è§‚æµ‹ç›¸å¯¹åŒ–
                buffer_pos_relative = []
                buffer_rot_relative = []
                for pos, rot6d in zip(buffer_pos, buffer_rot):
                    pose9 = np.concatenate([pos, rot6d])
                    SE3 = su.pose9_to_SE3(pose9)
                    SE3_relative = su.SE3_inv(base_SE3) @ SE3
                    pose9_relative = su.SE3_to_pose9(SE3_relative)
                    buffer_pos_relative.append(pose9_relative[:3])
                    buffer_rot_relative.append(pose9_relative[3:9])
                
                # âœ… ä½¿ç”¨ç›¸å¯¹åŒ–åçš„è§‚æµ‹æ„å»º batch
                obs_batch = {
                    "sparse": {
                        "rgb_0": torch.from_numpy(np.stack(list(buffer_rgb_0))).unsqueeze(0).float().to(device),
                        "rgb_1": torch.from_numpy(np.stack(list(buffer_rgb_1))).unsqueeze(0).float().to(device),
                        "robot0_eef_pos": torch.from_numpy(np.stack(buffer_pos_relative)).unsqueeze(0).float().to(device),  # â† ç›¸å¯¹åŒ–
                        "robot0_eef_rot_axis_angle": torch.from_numpy(np.stack(buffer_rot_relative)).unsqueeze(0).float().to(device),  # â† ç›¸å¯¹åŒ–
                        "robot0_eef_wrench": torch.from_numpy(np.stack(list(buffer_wrench))).unsqueeze(0).float().to(device)
                    }
                }

                # batch_dir = "/data/haoxiang/acp_test"
                # batch_file = "batch_0.npy"
                # batch_path = os.path.join(batch_dir, batch_file)
                # numpy_batch = np.load(batch_path, allow_pickle=True).item()

                # obs_batch = {
                #     "sparse": {
                #         key: torch.from_numpy(val).float().to(device) 
                #         for key, val in numpy_batch.items()
                #     }
                # }

                
                result = policy.predict_action(obs_batch)
                all_pred_actions = result['sparse'].squeeze(0).cpu().numpy()
                
                # # è½¬æ¢ä¸ºç»å¯¹åæ ‡
                # current_pos = buffer_pos[-1]
                # current_rot6d = buffer_rot[-1]
                # current_pose9 = np.concatenate([current_pos, current_rot6d])
                # current_SE3 = su.pose9_to_SE3(current_pose9)

                # âœ… æ³¨æ„ï¼šbase_SE3 å·²ç»åœ¨ä¸Šé¢è®¡ç®—äº†ï¼Œè¿™é‡Œç›´æ¥ç”¨
                current_SE3 = base_SE3  # å°±æ˜¯è§‚æµ‹åºåˆ—çš„æœ€åä¸€å¸§
                
                all_pred_actions_absolute = []
                for relative_action in all_pred_actions:
                    ref_pose9_rel = relative_action[0:9]
                    vt_pose9_rel = relative_action[9:18]
                    stiffness_val = relative_action[18]
                    
                    ref_SE3_rel = su.pose9_to_SE3(ref_pose9_rel)
                    vt_SE3_rel = su.pose9_to_SE3(vt_pose9_rel)
                    
                    ref_SE3_abs = current_SE3 @ ref_SE3_rel
                    vt_SE3_abs = current_SE3 @ vt_SE3_rel
                    
                    ref_pose9_abs = su.SE3_to_pose9(ref_SE3_abs)
                    vt_pose9_abs = su.SE3_to_pose9(vt_SE3_abs)
                    
                    absolute_action = np.concatenate([
                        ref_pose9_abs,
                        vt_pose9_abs,
                        [stiffness_val]
                    ])
                    all_pred_actions_absolute.append(absolute_action)
                
                all_pred_actions_absolute = np.array(all_pred_actions_absolute)
                
                steps_to_execute = all_pred_actions_absolute[:n_action_steps]
                for act in steps_to_execute:
                    action_queue.append(act)
            
            # ========================================
            # 4. ä»é˜Ÿåˆ—å–å‡ºä¸€ä¸ªåŠ¨ä½œ
            # ========================================
            if len(action_queue) == 0:
                continue
            
            predicted_action = action_queue.popleft()
            print(f"{t} pred action: \n {predicted_action}")
            
            # ========================================
            # 5. è·å– ground truthï¼ˆå¦‚æœæœ‰ï¼‰
            # ========================================
            # è·å– GT æ—¶ï¼Œä¼ å…¥å¯¹é½åçš„ robot_idx
            gt_pose, gt_vt, gt_stiff = replayer.get_ground_truth_action(robot_idx)
            
            # ========================================
            # 6. å¯¹æ¯”å’Œè®°å½•
            # ========================================
            pred_ref_pos = predicted_action[0:3]
            pred_vt_pos = predicted_action[9:12]
            pred_stiff = predicted_action[18]
            
            # print(f"  Current pos: {end_pos}")
            # print(f"  Predicted ref pos: {pred_ref_pos}")
            # print(f"  Predicted VT pos: {pred_vt_pos}")
            # print(f"  Predicted stiffness: {pred_stiff:.2f}")
            
            # if gt_vt is not None:
            #     gt_vt_pos = gt_vt[:3]
            #     print(f"  GT VT pos: {gt_vt_pos}")
            #     print(f"  GT stiffness: {gt_stiff:.2f}")
            #     print(f"  VT position error: {np.linalg.norm(pred_vt_pos - gt_vt_pos):.4f}")
            #     print(f"  Stiffness error: {abs(pred_stiff - gt_stiff):.2f}")
            
            # è®°å½•ç»“æœ
            results['predicted_actions'].append(predicted_action)
            if gt_pose is not None:
                results['ground_truth_actions'].append(gt_pose)
            if gt_vt is not None:
                results['predicted_vt'].append(pred_vt_pos)
                results['ground_truth_vt'].append(gt_vt[:3])
                results['predicted_stiffness'].append(pred_stiff)
                results['ground_truth_stiffness'].append(gt_stiff)
    
    # ========================================
    # 7. æ±‡æ€»ç»“æœ
    # ========================================
    # print("\n" + "=" * 60)
    # print("Evaluation Summary")
    # print("=" * 60)
    
    # if len(results['ground_truth_vt']) > 0:
    #     vt_errors = [np.linalg.norm(np.array(p) - np.array(g)) 
    #                  for p, g in zip(results['predicted_vt'], results['ground_truth_vt'])]
    #     stiff_errors = [abs(p - g) 
    #                    for p, g in zip(results['predicted_stiffness'], results['ground_truth_stiffness'])]
        
    #     print(f"Virtual Target Position Error:")
    #     print(f"  Mean: {np.mean(vt_errors):.4f} m")
    #     print(f"  Std:  {np.std(vt_errors):.4f} m")
    #     print(f"  Max:  {np.max(vt_errors):.4f} m")
        
    #     print(f"\nStiffness Error:")
    #     print(f"  Mean: {np.mean(stiff_errors):.2f}")
    #     print(f"  Std:  {np.std(stiff_errors):.2f}")
    #     print(f"  Max:  {np.max(stiff_errors):.2f}")
    
    # # ä¿å­˜ç»“æœ
    # output_path = f"eval_results_{episode_id}.npz"
    # np.savez(output_path, **results)
    # print(f"\nResults saved to: {output_path}")

    # ========================================
    # 7. æ‰“å°å’Œå¯è§†åŒ–åŠ¨ä½œåºåˆ—
    # ========================================
    print("\n" + "=" * 60)
    print("Action Sequence Analysis")
    print("=" * 60)

    print("\n=== DEBUG: results å­—å…¸çš„é”®å ===")
    print("Keys in results:", results.keys())
    print("================================\n")

    input("press enter")

    if len(results['ground_truth_vt']) > 0:
        # è½¬æ¢ä¸º numpy æ•°ç»„
        gt_ref = []
        gt_vt = []
        gt_stiff = []
        pred_ref = []
        pred_vt = []
        pred_stiff = []
        
        # ä»è®°å½•çš„åŠ¨ä½œä¸­æå–ä½ç½®
        for action in results['ground_truth_actions']:
            gt_ref.append(action[:3])  # å‚è€ƒä½å§¿çš„ xyz
        
        for action in results['predicted_actions']:
            pred_ref.append(action[:3])  # é¢„æµ‹å‚è€ƒä½å§¿çš„ xyz
        
        gt_ref = np.array(gt_ref)
        gt_vt = np.array(results['ground_truth_vt'])
        gt_stiff = np.array(results['ground_truth_stiffness'])
        
        pred_ref = np.array(pred_ref)
        pred_vt = np.array(results['predicted_vt'])
        pred_stiff = np.array(results['predicted_stiffness'])
            
        # è®¡ç®—è¯¯å·®
        ref_errors = np.linalg.norm(pred_ref - gt_ref, axis=1)
        vt_errors = np.linalg.norm(pred_vt - gt_vt, axis=1)
        stiff_errors = np.abs(pred_stiff - gt_stiff)
        
        # ========================================
        # æ‰“å°åŠ¨ä½œåºåˆ—ç»Ÿè®¡
        # ========================================
        print(f"\nTotal Steps: {len(gt_vt)}")
        print(f"\nReference Pose Statistics:")
        print(f"  X range: [{gt_ref[:, 0].min():.3f}, {gt_ref[:, 0].max():.3f}] m")
        print(f"  Y range: [{gt_ref[:, 1].min():.3f}, {gt_ref[:, 1].max():.3f}] m")
        print(f"  Z range: [{gt_ref[:, 2].min():.3f}, {gt_ref[:, 2].max():.3f}] m")
        
        print(f"\nVirtual Target Statistics:")
        print(f"  X range: [{gt_vt[:, 0].min():.3f}, {gt_vt[:, 0].max():.3f}] m")
        print(f"  Y range: [{gt_vt[:, 1].min():.3f}, {gt_vt[:, 1].max():.3f}] m")
        print(f"  Z range: [{gt_vt[:, 2].min():.3f}, {gt_vt[:, 2].max():.3f}] m")
        
        print(f"\nStiffness Statistics:")
        print(f"  Range: [{gt_stiff.min():.2f}, {gt_stiff.max():.2f}]")
        print(f"  Mean:  {gt_stiff.mean():.2f}")
        print(f"  Std:   {gt_stiff.std():.2f}")
        
        # ========================================
        # æ‰“å°é¢„æµ‹è¯¯å·®
        # ========================================
        print(f"\n{'='*60}")
        print("Prediction Errors:")
        print(f"{'='*60}")
        print(f"Reference Position Error:")
        print(f"  Mean: {np.mean(ref_errors)*1000:.2f} mm")
        print(f"  Max:  {np.max(ref_errors)*1000:.2f} mm")
        
        print(f"\nVirtual Target Position Error:")
        print(f"  Mean: {np.mean(vt_errors)*1000:.2f} mm")
        print(f"  Max:  {np.max(vt_errors)*1000:.2f} mm")
        
        print(f"\nStiffness Error:")
        print(f"  Mean: {np.mean(stiff_errors):.2f}")
        print(f"  Max:  {np.max(stiff_errors):.2f}")
        
        # ========================================
        # æ‰“å°å‡ ä¸ªå…³é”®æ—¶åˆ»çš„åŠ¨ä½œåºåˆ—
        # ========================================
        print(f"\n{'='*60}")
        print("Sample Action Sequences (every 20 steps):")
        print(f"{'='*60}")
        for i in range(0, len(gt_vt), 20):
            print(f"\nStep {i}:")
            print(f"  GT Ref:  [{gt_ref[i, 0]:.3f}, {gt_ref[i, 1]:.3f}, {gt_ref[i, 2]:.3f}]")
            print(f"  Pred Ref:[{pred_ref[i, 0]:.3f}, {pred_ref[i, 1]:.3f}, {pred_ref[i, 2]:.3f}]  Error: {ref_errors[i]*1000:.2f} mm")
            print(f"  GT VT:   [{gt_vt[i, 0]:.3f}, {gt_vt[i, 1]:.3f}, {gt_vt[i, 2]:.3f}]")
            print(f"  Pred VT: [{pred_vt[i, 0]:.3f}, {pred_vt[i, 1]:.3f}, {pred_vt[i, 2]:.3f}]  Error: {vt_errors[i]*1000:.2f} mm")
            print(f"  GT Stiff:   {gt_stiff[i]:.2f}")
            print(f"  Pred Stiff: {pred_stiff[i]:.2f}  Error: {stiff_errors[i]:.2f}")
        
        # ========================================
        # å¯è§†åŒ–åŠ¨ä½œåºåˆ—å¹¶ä¿å­˜å›¾ç‰‡
        # ========================================
        import matplotlib
        matplotlib.use('Agg')
        import matplotlib.pyplot as plt
        from mpl_toolkits.mplot3d import Axes3D
        
        fig = plt.figure(figsize=(20, 12))
        
        # ----------------
        # 1. Reference Pose 3D è½¨è¿¹
        # ----------------
        ax1 = fig.add_subplot(2, 4, 1, projection='3d')
        ax1.plot(gt_ref[:, 0], gt_ref[:, 1], gt_ref[:, 2], 
                'b-', label='GT Ref', linewidth=2.5, alpha=0.8)
        ax1.plot(pred_ref[:, 0], pred_ref[:, 1], pred_ref[:, 2], 
                'r--', label='Pred Ref', linewidth=2, alpha=0.8)
        ax1.scatter(gt_ref[0, 0], gt_ref[0, 1], gt_ref[0, 2], 
                    c='green', s=150, marker='o', label='Start', edgecolors='black', linewidths=2)
        ax1.scatter(gt_ref[-1, 0], gt_ref[-1, 1], gt_ref[-1, 2], 
                    c='red', s=150, marker='s', label='End', edgecolors='black', linewidths=2)
        ax1.set_xlabel('X (m)', fontsize=11)
        ax1.set_ylabel('Y (m)', fontsize=11)
        ax1.set_zlabel('Z (m)', fontsize=11)
        ax1.legend(fontsize=9)
        ax1.set_title('Reference Pose Trajectory', fontsize=13, fontweight='bold')
        ax1.grid(True, alpha=0.3)
        
        # ----------------
        # 2. Virtual Target 3D è½¨è¿¹
        # ----------------
        ax2 = fig.add_subplot(2, 4, 2, projection='3d')
        ax2.plot(gt_vt[:, 0], gt_vt[:, 1], gt_vt[:, 2], 
                'b-', label='GT VT', linewidth=2.5, alpha=0.8)
        ax2.plot(pred_vt[:, 0], pred_vt[:, 1], pred_vt[:, 2], 
                'r--', label='Pred VT', linewidth=2, alpha=0.8)
        ax2.scatter(gt_vt[0, 0], gt_vt[0, 1], gt_vt[0, 2], 
                    c='green', s=150, marker='o', label='Start', edgecolors='black', linewidths=2)
        ax2.scatter(gt_vt[-1, 0], gt_vt[-1, 1], gt_vt[-1, 2], 
                    c='red', s=150, marker='s', label='End', edgecolors='black', linewidths=2)
        ax2.set_xlabel('X (m)', fontsize=11)
        ax2.set_ylabel('Y (m)', fontsize=11)
        ax2.set_zlabel('Z (m)', fontsize=11)
        ax2.legend(fontsize=9)
        ax2.set_title('Virtual Target Trajectory', fontsize=13, fontweight='bold')
        ax2.grid(True, alpha=0.3)
        
        # ----------------
        # 3. Reference Pose XYZ åˆ†é‡
        # ----------------
        time_steps = np.arange(len(gt_ref))
        
        ax3 = fig.add_subplot(2, 4, 3)
        ax3.plot(time_steps, gt_ref[:, 0], 'b-', label='GT X', linewidth=2)
        ax3.plot(time_steps, pred_ref[:, 0], 'r--', label='Pred X', linewidth=2, alpha=0.8)
        ax3.set_xlabel('Time Step', fontsize=10)
        ax3.set_ylabel('X Position (m)', fontsize=10)
        ax3.legend(fontsize=9)
        ax3.set_title('Reference Pose - X axis', fontsize=11)
        ax3.grid(True, alpha=0.3)
        
        ax4 = fig.add_subplot(2, 4, 4)
        ax4.plot(time_steps, gt_ref[:, 1], 'b-', label='GT Y', linewidth=2)
        ax4.plot(time_steps, pred_ref[:, 1], 'r--', label='Pred Y', linewidth=2, alpha=0.8)
        ax4.set_xlabel('Time Step', fontsize=10)
        ax4.set_ylabel('Y Position (m)', fontsize=10)
        ax4.legend(fontsize=9)
        ax4.set_title('Reference Pose - Y axis', fontsize=11)
        ax4.grid(True, alpha=0.3)
        
        ax5 = fig.add_subplot(2, 4, 5)
        ax5.plot(time_steps, gt_ref[:, 2], 'b-', label='GT Z', linewidth=2)
        ax5.plot(time_steps, pred_ref[:, 2], 'r--', label='Pred Z', linewidth=2, alpha=0.8)
        ax5.set_xlabel('Time Step', fontsize=10)
        ax5.set_ylabel('Z Position (m)', fontsize=10)
        ax5.legend(fontsize=9)
        ax5.set_title('Reference Pose - Z axis', fontsize=11)
        ax5.grid(True, alpha=0.3)
        
        # ----------------
        # 4. Virtual Target XYZ åˆ†é‡
        # ----------------
        ax6 = fig.add_subplot(2, 4, 6)
        ax6.plot(time_steps, gt_vt[:, 0], 'b-', label='GT X', linewidth=2)
        ax6.plot(time_steps, pred_vt[:, 0], 'r--', label='Pred X', linewidth=2, alpha=0.8)
        ax6.set_xlabel('Time Step', fontsize=10)
        ax6.set_ylabel('X Position (m)', fontsize=10)
        ax6.legend(fontsize=9)
        ax6.set_title('Virtual Target - X axis', fontsize=11)
        ax6.grid(True, alpha=0.3)
        
        ax7 = fig.add_subplot(2, 4, 7)
        ax7.plot(time_steps, gt_vt[:, 1], 'b-', label='GT Y', linewidth=2)
        ax7.plot(time_steps, pred_vt[:, 1], 'r--', label='Pred Y', linewidth=2, alpha=0.8)
        ax7.set_xlabel('Time Step', fontsize=10)
        ax7.set_ylabel('Y Position (m)', fontsize=10)
        ax7.legend(fontsize=9)
        ax7.set_title('Virtual Target - Y axis', fontsize=11)
        ax7.grid(True, alpha=0.3)
        
        ax8 = fig.add_subplot(2, 4, 8)
        ax8.plot(time_steps, gt_vt[:, 2], 'b-', label='GT Z', linewidth=2)
        ax8.plot(time_steps, pred_vt[:, 2], 'r--', label='Pred Z', linewidth=2, alpha=0.8)
        ax8.set_xlabel('Time Step', fontsize=10)
        ax8.set_ylabel('Z Position (m)', fontsize=10)
        ax8.legend(fontsize=9)
        ax8.set_title('Virtual Target - Z axis', fontsize=11)
        ax8.grid(True, alpha=0.3)
        
        plt.suptitle(f'Action Sequence Visualization - {episode_id}', 
                    fontsize=16, fontweight='bold', y=0.995)
        plt.tight_layout(rect=[0, 0, 1, 0.99])
        
        fig_path = f"action_sequence_{episode_id}.png"
        plt.savefig(fig_path, dpi=150, bbox_inches='tight')
        plt.close()
        print(f"\nâœ… Action sequence visualization saved to: {fig_path}")
        
        # ========================================
        # ç¬¬äºŒå¼ å›¾ï¼šåˆšåº¦åºåˆ—
        # ========================================
        fig2 = plt.figure(figsize=(16, 10))
        
        # åˆšåº¦å¯¹æ¯”
        ax1 = fig2.add_subplot(2, 2, 1)
        ax1.plot(time_steps, gt_stiff, 'b-', label='Ground Truth', linewidth=2.5)
        ax1.plot(time_steps, pred_stiff, 'r--', label='Predicted', linewidth=2)
        ax1.fill_between(time_steps, gt_stiff, pred_stiff, alpha=0.2, color='gray')
        ax1.set_xlabel('Time Step', fontsize=11)
        ax1.set_ylabel('Stiffness', fontsize=11)
        ax1.legend(fontsize=10)
        ax1.set_title('Stiffness Sequence', fontsize=13, fontweight='bold')
        ax1.grid(True, alpha=0.3)
        
        # åˆšåº¦è¯¯å·®
        ax2 = fig2.add_subplot(2, 2, 2)
        ax2.plot(time_steps, stiff_errors, 'purple', linewidth=2)
        ax2.axhline(np.mean(stiff_errors), color='red', linestyle='--', 
                    linewidth=2, label=f'Mean: {np.mean(stiff_errors):.2f}')
        ax2.set_xlabel('Time Step', fontsize=11)
        ax2.set_ylabel('Stiffness Error', fontsize=11)
        ax2.legend(fontsize=10)
        ax2.set_title('Stiffness Prediction Error', fontsize=13, fontweight='bold')
        ax2.grid(True, alpha=0.3)
        
        # ä½ç½®è¯¯å·®å¯¹æ¯”
        ax3 = fig2.add_subplot(2, 2, 3)
        ax3.plot(time_steps, ref_errors * 1000, 'b-', label='Ref Pose Error', linewidth=2)
        ax3.plot(time_steps, vt_errors * 1000, 'r-', label='VT Error', linewidth=2)
        ax3.axhline(np.mean(ref_errors) * 1000, color='blue', linestyle='--', 
                    alpha=0.5, label=f'Ref Mean: {np.mean(ref_errors)*1000:.2f} mm')
        ax3.axhline(np.mean(vt_errors) * 1000, color='red', linestyle='--', 
                    alpha=0.5, label=f'VT Mean: {np.mean(vt_errors)*1000:.2f} mm')
        ax3.set_xlabel('Time Step', fontsize=11)
        ax3.set_ylabel('Position Error (mm)', fontsize=11)
        ax3.legend(fontsize=9)
        ax3.set_title('Position Prediction Errors', fontsize=13, fontweight='bold')
        ax3.grid(True, alpha=0.3)
        
        # è¯¯å·®åˆ†å¸ƒç›´æ–¹å›¾
        ax4 = fig2.add_subplot(2, 2, 4)
        ax4.hist(vt_errors * 1000, bins=30, color='skyblue', edgecolor='black', 
                alpha=0.7, label='VT Error')
        ax4.axvline(np.mean(vt_errors) * 1000, color='red', linestyle='--', 
                    linewidth=2.5, label=f'Mean: {np.mean(vt_errors)*1000:.2f} mm')
        ax4.axvline(np.median(vt_errors) * 1000, color='orange', linestyle='--', 
                    linewidth=2.5, label=f'Median: {np.median(vt_errors)*1000:.2f} mm')
        ax4.set_xlabel('VT Position Error (mm)', fontsize=11)
        ax4.set_ylabel('Frequency', fontsize=11)
        ax4.legend(fontsize=10)
        ax4.set_title('VT Error Distribution', fontsize=13, fontweight='bold')
        ax4.grid(True, alpha=0.3)
        
        plt.suptitle(f'Stiffness and Error Analysis - {episode_id}', 
                    fontsize=16, fontweight='bold', y=0.995)
        plt.tight_layout(rect=[0, 0, 1, 0.99])
        
        stiff_path = f"stiffness_analysis_{episode_id}.png"
        plt.savefig(stiff_path, dpi=150, bbox_inches='tight')
        plt.close()
        print(f"âœ… Stiffness analysis saved to: {stiff_path}")

    # ä¿å­˜åŸå§‹æ•°ç»„æ•°æ®ï¼ˆæ–¹ä¾¿åç»­åˆ†æï¼‰
    output_path = f"action_sequence_data_{episode_id}.npz"
    np.savez(output_path, **results)
    print(f"âœ… Raw action data saved to: {output_path}")

    print("\n" + "=" * 60)
    print("All files saved!")
    print("=" * 60)
    print(f"1. Action sequence visualization: {fig_path}")
    print(f"2. Stiffness analysis:             {stiff_path}")
    print(f"3. Raw numpy data:                 {output_path}")
    print("=" * 60)


if __name__ == '__main__':
    register_codecs()
    reset_buffers()
    evaluate_with_dataset()