import sys
import os

SCRIPT_PATH = os.path.abspath(os.path.dirname(__file__))
sys.path.append(os.path.join(SCRIPT_PATH, "../../"))

from PyriteUtility.data_pipeline.episode_data_buffer import (
    VideoData,
    EpisodeDataBuffer,
)
from PyriteUtility.planning_control.filtering import LiveLPFilter

import pathlib
import shutil
import numpy as np
import pandas as pd
import zarr
import cv2
import concurrent.futures

# check environment variables
if "PYRITE_RAW_DATASET_FOLDERS" not in os.environ:
    raise ValueError("Please set the environment variable PYRITE_RAW_DATASET_FOLDERS")
if "PYRITE_DATASET_FOLDERS" not in os.environ:
    raise ValueError("Please set the environment variable PYRITE_DATASET_FOLDERS")


# def image_read(rgb_dir, rgb_file_list, i, output_data_rgb, output_data_rgb_time_stamps):
#     img_name = rgb_file_list[i]
#     img = cv2.imread(str(rgb_dir.joinpath(img_name)))
#     # convert BGR to RGB for imageio
#     output_data_rgb[i] = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
#     time_img_ms = float(img_name[11:22])
#     # img_000695_29345.186724_ms
#     # ËøôÈáåÊèêÂèñÂá∫‰∫ÜÊãçÊëÑÊó∂Èó¥
#     output_data_rgb_time_stamps[i] = time_img_ms
#     return True

def image_read(rgb_dir, rgb_file_list, i, output_data_rgb, output_data_rgb_time_stamps):
    img_name = rgb_file_list[i]
    img = cv2.imread(str(rgb_dir.joinpath(img_name)))

    if img is None:
        print(f"Error: Failed to read {img_name}")
        return False
    # convert BGR to RGB for imageio
    output_data_rgb[i] = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

    # time_img_ms = float(img_name[11:22])
    # output_data_rgb_time_stamps[i] = time_img_ms

    try:
        # time_img_ms = float(img_name.split('.')[0])
        time_img_ms = int(img_name.split('.')[0])
        output_data_rgb_time_stamps[i] = float(time_img_ms)
    except ValueError:
        print(f"Error: Could not parse timestamp from {img_name}")
        return False

    return True


# specify the input and output directories
robot_id_list = [0]  # single robot
camera_id_list = [0,1] # inhand and global
# id_list = [0, 1] # bimanual

input_dir = pathlib.Path(
    os.environ.get("PYRITE_RAW_DATASET_FOLDERS") + "/shovel/train"
)
output_dir = pathlib.Path(os.environ.get("PYRITE_DATASET_FOLDERS") + "/shovel_acp_processed")

robot_timestamp_dir = output_dir.joinpath("robot_timestamp")
wrench_timestamp_dir = output_dir.joinpath("wrench_timestamp")
rgb_timestamp_dir = output_dir.joinpath("rgb_timestamp")

# clean and create output folders
if os.path.exists(output_dir):
    shutil.rmtree(output_dir)


# # check for black images
# def check_black_images(rgb_file_list, rgb_dir, i, prefix):
#     f = rgb_file_list[i]
#     img = cv2.imread(str(rgb_dir.joinpath(f)))
#     # print the mean of the image
#     img_mean = np.mean(img)
#     if img_mean < 50:
#         print(f"{prefix}, {f} has mean value of {img_mean}")
#     return True


# for episode_name in os.listdir(input_dir):
#     if episode_name.startswith("."):
#         continue

#     episode_dir = input_dir.joinpath(episode_name)
#     for id in id_list:
#         rgb_dir = episode_dir.joinpath("rgb_" + str(id))
#         rgb_file_list = os.listdir(rgb_dir)
#         num_raw_images = len(rgb_file_list)
#         print(f"Checking for black images in {rgb_dir}")
#         with concurrent.futures.ThreadPoolExecutor(max_workers=32) as executor:
#             futures = set()
#             for i in range(len(rgb_file_list)):
#                 futures.add(
#                     executor.submit(
#                         check_black_images,
#                         rgb_file_list,
#                         rgb_dir,
#                         i,
#                         f"{episode_name} rgb_{id}",
#                     )
#                 )

#             completed, futures = concurrent.futures.wait(futures)
#             for f in completed:
#                 if not f.result():
#                     raise RuntimeError("Failed to read image!")
# exit()


# open the zarr store
store = zarr.DirectoryStore(path=output_dir)
root = zarr.open(store=store, mode="a")

print("Reading data from input_dir: ", input_dir)
episode_names = os.listdir(input_dir)


def process_one_episode(root, episode_name, input_dir, robot_id_list, camera_id_list):
    if episode_name.startswith("."):
        return True

    # info about input
    # episode_id = episode_name[8:]
    # print(f"episode_name: {episode_name}, episode_id: {episode_id}")
    # episode_dir = input_dir.joinpath(episode_name)

    # acpÁöÑÊ†ºÂºè
    # episode_1727294514
    # Ëøô‰∏™ËÄÉËôë‰øÆÊîπ‰∏äÈù¢ÈÇ£‰∏™Ë∑ØÂæÑËØªÂèñÈÄªËæë
    # scene_0001

    # üî• ‰øÆÊ≠£Ôºöscene_0001 ‚Üí episode_id = 1
    episode_id = int(episode_name.split('_')[-1])
    print(f"scene_name: {episode_name}, scene_id: {episode_id}")
    episode_dir = input_dir.joinpath(episode_name)

    # read rgb
    data_rgb = []
    data_rgb_time_stamps = []
    rgb_data_shapes = []
    for id in camera_id_list:

        if id == 0:
            cam_name = "cam_104122060902"
        elif id == 1:
            cam_name = "cam_104122064489"
        else:  
            print("id error")
            break

        rgb_dir = episode_dir.joinpath(cam_name).joinpath("color")
        rgb_file_list = os.listdir(rgb_dir)
        rgb_file_list.sort()  # important!
        num_raw_images = len(rgb_file_list)
        img = cv2.imread(str(rgb_dir.joinpath(rgb_file_list[0])))

        rgb_data_shapes.append((num_raw_images, *img.shape))
        data_rgb.append(np.zeros(rgb_data_shapes[id], dtype=np.uint8))
        data_rgb_time_stamps.append(np.zeros(num_raw_images))

        print(f"Reading rgb data from: {rgb_dir}")
        with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:
            futures = set()
            for i in range(len(rgb_file_list)):
                futures.add(
                    executor.submit(
                        image_read,
                        rgb_dir,
                        rgb_file_list,
                        i,
                        data_rgb[id],
                        data_rgb_time_stamps[id],
                    )
                )

            completed, futures = concurrent.futures.wait(futures)
            for f in completed:
                if not f.result():
                    raise RuntimeError("Failed to read image!")

    # read low dim data
    data_ts_pose_fb = []
    data_robot_time_stamps = []
    data_wrench = []
    data_wrench_time_stamps = []
    print(f"Reading low dim data for : {episode_dir}")
    for id in robot_id_list:
        json_path = episode_dir.joinpath("robot_data_" + str(id) + ".json")
        df_robot_data = pd.read_json(json_path)
        data_robot_time_stamps.append(df_robot_data["robot_time_stamps"].to_numpy())
        data_ts_pose_fb.append(np.vstack(df_robot_data["ts_pose_fb"]))

        # read wrench data
        json_path = episode_dir.joinpath("wrench_data_" + str(id) + ".json")
        df_wrench_data = pd.read_json(json_path)
        data_wrench_time_stamps.append(df_wrench_data["wrench_time_stamps"].to_numpy())
        data_wrench.append(np.vstack(df_wrench_data["wrench"]))

    # get filtered force
    print(f"Computing filtered wrench for {episode_name}")

    # ‰∏ãÈù¢Ëøô‰∏™paraÂÖ∂ÂÆûÊ≤°Ë¢´Áî®Âà∞

    force_filtering_para = {
        "sampling_freq": 100,
        "cutoff_freq": 5,
        "order": 5,
    }

    ft_filter = LiveLPFilter(
        fs=1000,      # Êàë‰ª¨ÁöÑlowdimÊúâ1000hz
        cutoff=5,    # Êà™Ê≠¢È¢ëÁéá (Cutoff Frequency) ‰∏∫ 5Hz
        order=5,     # Êª§Ê≥¢Âô®Èò∂Êï∞ (Order)
        dim=6,       # Áª¥Â∫¶ (Dimension) ‰∏∫ 6
    )
    data_wrench_filtered = []
    for id in robot_id_list:
        data_wrench_filtered.append(np.array([ft_filter(y) for y in data_wrench[id]]))

    # make time stamps start from zero
    # Ëøô‰∏ÄÈÉ®ÂàÜËÆ©Â§ßÊï∞ÂèòÂ∞èÔºåÂêåÊó∂ËÆ©Êó∂Èó¥ÈÉΩ‰ªé‰ª•0‰∏∫ÂèÇËÄÉÂÄº
    # Âç≥‰ΩøÂºÄÂßãËÆ∞ÂΩïÁöÑÊó∂Èó¥‰∏ç‰∏ÄÊ†∑ÔºåËá≥Â∞ëÊúâ‰∏Ä‰∏™Êó∂Èó¥Êà≥Êï∞ÁªÑ‰ªé0ÂºÄÂßãÔºåÂÖ∂‰ªñÁöÑÂ∫îËØ•‰πüÊé•Ëøë0
    time_offsets = []

    for cam_id in camera_id_list:
        time_offsets.append(data_rgb_time_stamps[cam_id][0])
    for robot_id in robot_id_list:
        time_offsets.append(data_robot_time_stamps[robot_id][0])
        time_offsets.append(data_wrench_time_stamps[robot_id][0])

    time_offset = np.min(time_offsets)

    # üî• ‰øÆÂ§çÔºöËΩ¨Êç¢‰∏∫ float ÂêéÂÜçÂáè
    for cam_id in camera_id_list:
        data_rgb_time_stamps[cam_id] = data_rgb_time_stamps[cam_id].astype(float) - time_offset
    for robot_id in robot_id_list:
        data_robot_time_stamps[robot_id] = data_robot_time_stamps[robot_id].astype(float) - time_offset
        data_wrench_time_stamps[robot_id] = data_wrench_time_stamps[robot_id].astype(float) - time_offset

    # create output zarr
    print(f"Saving everything to : {output_dir}")
    recoder_buffer = EpisodeDataBuffer(
        store_path=output_dir,
        camera_ids=camera_id_list,
        save_video=True,
        save_video_fps=60,
        data=root,
    )

    # save data using recoder_buffer
    rgb_data_buffer = {}
    for cam_id in camera_id_list:
        rgb_data_buffer[cam_id] = VideoData(rgb=data_rgb[cam_id], camera_id=cam_id)
    
    recoder_buffer.create_zarr_groups_for_episode(rgb_data_shapes, camera_id_list, episode_id)
    recoder_buffer.save_video_for_episode(
        visual_observations=rgb_data_buffer,
        visual_time_stamps=data_rgb_time_stamps,
        episode_id=episode_id,
    )
    recoder_buffer.save_low_dim_for_episode(
        ts_pose_command=data_ts_pose_fb,
        ts_pose_fb=data_ts_pose_fb,
        wrench=data_wrench,
        wrench_filtered=data_wrench_filtered,
        robot_time_stamps=data_robot_time_stamps,
        wrench_time_stamps=data_wrench_time_stamps,
        episode_id=episode_id,
    )
    return True


with concurrent.futures.ProcessPoolExecutor(max_workers=3) as executor:
    futures = [
        executor.submit(
            process_one_episode,
            root,
            episode_name,
            input_dir,
            robot_id_list,
            camera_id_list,
        )
        for episode_name in episode_names
    ]
    for future in concurrent.futures.as_completed(futures):
        if not future.result():
            raise RuntimeError("Multi-processing failed!")

print("Finished reading. Now start generating metadata")
from PyriteUtility.computer_vision.imagecodecs_numcodecs import register_codecs

register_codecs()
buffer = zarr.open(output_dir)
meta = buffer.create_group("meta", overwrite=True)
episode_robot_len = []
episode_wrench_len = []
episode_rgb_len = []

for id in robot_id_list:
    episode_robot_len.append([])
    episode_wrench_len.append([])

for cam_id in camera_id_list: 
    episode_rgb_len.append([])

# ÁªüËÆ°Êó∂
count = 0
for key in buffer["data"].keys():
    episode = key
    ep_data = buffer["data"][episode]

    for robot_id in robot_id_list:
        episode_robot_len[robot_id].append(ep_data[f"ts_pose_fb_{robot_id}"].shape[0])
        episode_wrench_len[robot_id].append(ep_data[f"wrench_{robot_id}"].shape[0])
    
    for cam_id in camera_id_list:  # ‚Üê ÊîπËøôÈáå
        episode_rgb_len[cam_id].append(ep_data[f"rgb_{cam_id}"].shape[0])
        
    print(f"Episode {count}: {episode}")
    for robot_id in robot_id_list:
        print(f"  Robot {robot_id}: len={episode_robot_len[robot_id][-1]}")
    for cam_id in camera_id_list:
        print(f"  Camera {cam_id}: len={episode_rgb_len[cam_id][-1]}")
    count += 1

for id in robot_id_list:
    meta[f"episode_robot{id}_len"] = zarr.array(episode_robot_len[id])
    meta[f"episode_wrench{id}_len"] = zarr.array(episode_wrench_len[id])

for cam_id in camera_id_list:  # ‚Üê ÊîπËøôÈáå
    meta[f"episode_rgb{cam_id}_len"] = zarr.array(episode_rgb_len[cam_id])

print(f"All done! Generated {count} episodes in {output_dir}")
print("The only thing left is to run postprocess_add_virtual_target_label.py")
